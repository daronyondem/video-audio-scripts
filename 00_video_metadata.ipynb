{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import langchain as lc\n",
    "from langchain.document_loaders import SRTLoader\n",
    "from dotenv import load_dotenv\n",
    "import srt\n",
    "import codecs\n",
    "import tiktoken\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "#model_name = \"gpt-3.5-turbo-16k\"\n",
    "model_name = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating video chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:08:11 Ülke ve Yasaların Etkisi]\n",
      "[0:08:20 Tazminat ve Bütçe Planlaması]\n",
      "[0:08:49 Performansa Dayalı Bonuslar ve Takım Bonusları]\n",
      "[0:09:17 Yan Haklar ve Ücretli İzinler]\n",
      "[0:09:42 Enflasyon ve Maaş Eşitliği]\n",
      "[0:14:35 İç ve Dış Çalışan Maaşları Arasındaki Fark]\n",
      "[0:16:49 İnsan Kaynakları ve Finansın İşbirliği]\n",
      "[0:17:23 Küçük Start-up'larda Maaş Planlaması]\n",
      "[0:17:48 Ücret Eşitliği ve Demografik Eşitsizlikler]\n",
      "[0:18:35 Şirket İçi Maaş Hizalanması ve Finansal Hesaplama Problemleri]\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model= model_name,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def process_srt_file(file_path):\n",
    "    # Read and parse SRT file\n",
    "    with codecs.open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        file_content = f.read()\n",
    "        subtitle_generator = srt.parse(file_content)\n",
    "        subtitles = list(subtitle_generator)\n",
    "    \n",
    "    result = \"\"\n",
    "    chunk = \"\"\n",
    "    for sub in subtitles:\n",
    "        chunk += str(sub.start) + \">\" + str(sub.end.total_seconds) + \"\\\\n\" + sub.content\n",
    "        if num_tokens_from_string(chunk) > 7000:\n",
    "            prompt = \"Below is a part of a video transcript. You need to split the video into five topic chapters. The chapters will be used to navigate in the larger video timeline to let watchers switch between topics. Read the entire transcript. Once done reading, split it into chapters. Provide the list of chapters in this format [HH:MM:SS Chapter Name]. Put each chapter in a separate line in plain text. Match the transcript language in the output.\\\\n\\\\n\" + chunk\n",
    "            completion = get_completion(prompt)\n",
    "            result += completion\n",
    "            clear_output(wait=True)\n",
    "            print(completion)\n",
    "            chunk = \"\"        \n",
    "\n",
    "    return result\n",
    "\n",
    "final_output = process_srt_file(\"output_audio.srt\")\n",
    "with open('chapters.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating video summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video discusses the complexities of salary calculations and adjustments within a company. It emphasizes the importance of considering factors such as legal requirements, potential severance payments, performance-based bonuses, and inflation. The speaker also highlights the need for regular reviews of salary equality within the company to prevent disparities between new and existing employees. The video further discusses the concept of a healthy turnover rate and the necessity of aligning internal and external salary evaluations. The speaker concludes by stating that discrepancies in salary adjustments are financial calculation problems, not cultural ones.\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model= model_name,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def process_srt_file(file_path):\n",
    "    # Read and parse SRT file\n",
    "    with codecs.open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        file_content = f.read()\n",
    "        subtitle_generator = srt.parse(file_content)\n",
    "        subtitles = list(subtitle_generator)\n",
    "    \n",
    "    result = \"\"\n",
    "    chunk = \"\"\n",
    "    for sub in subtitles:\n",
    "        chunk += str(sub.start) + \">\" + str(sub.end.total_seconds) + \"\\\\n\" + sub.content\n",
    "        if num_tokens_from_string(chunk) > 7000:\n",
    "            prompt = \"Below is a part of a video transcript. Your goal is to summarize the entire video. You need to create the shortest summary of this section as possible that you will combine with other sections to create the full summary of the entire video.\\\\n\\\\n\" + chunk\n",
    "            completion = get_completion(prompt)\n",
    "            result += completion\n",
    "            clear_output(wait=True)\n",
    "            print(completion)\n",
    "            chunk = \"\"        \n",
    "\n",
    "    return result\n",
    "\n",
    "final_output = process_srt_file(\"output_audio.srt\")\n",
    "with open('summaries.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model= model_name,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def process_srt_file(file_path):\n",
    "    content = \"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    result = \"\"\n",
    "    prompt = \"Below is a series of summaries created out of different section of a video recording. The video is published on Youtube. Provide 10 TUrkish title alternatives and a single Turkish summary for the video. Both title and summary should be inviting and helpful to watchers. \\\\n\\\\n\" + content\n",
    "    result = get_completion(prompt)\n",
    "\n",
    "    return result\n",
    "\n",
    "final_output = process_srt_file(\"summaries.txt\")\n",
    "with open('title-description.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio download from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "\n",
    "# YouTube video url\n",
    "url = 'https://www.youtube.com/watch?v=R--fSB7CBIs'\n",
    "\n",
    "def download_audio(youtube_link):\n",
    "    youtube = YouTube(youtube_link)\n",
    "    audio_stream = youtube.streams.filter(only_audio=True).first()\n",
    "    # Save as .webm\n",
    "    audio_stream.download(filename=\"audio.mp4\")\n",
    "\n",
    "download_audio(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Audio from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in output_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def extract_audio(video_file, audio_file):\n",
    "    video = VideoFileClip(video_file)\n",
    "    audio = video.audio\n",
    "    audio.write_audiofile(audio_file)\n",
    "\n",
    "# usage\n",
    "extract_audio('C:\\\\Users\\\\daronyondem\\\\Videos\\\\2023-09-11-Maaslar-Nasil-Belirleniyor2.mp4', 'output_audio.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Split for Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='output_audio_10.mp3'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "song = AudioSegment.from_mp3(\"C:\\\\github\\\\dy\\\\video-transcript-analzyer\\\\output_audio.mp3\")\n",
    "\n",
    "# PyDub handles time in milliseconds\n",
    "ten_minutes = 10 * 60 * 1000\n",
    "\n",
    "first_10_minutes = song[:ten_minutes]\n",
    "\n",
    "first_10_minutes.export(\"output_audio_10.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [02:04<00:00, 12.2MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from whisper.utils import get_writer\n",
    "from pydub import AudioSegment\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "audio = \"C:\\\\github\\\\dy\\\\video-transcript-analzyer\\\\output_audio.mp3\"\n",
    "result = model.transcribe(audio)\n",
    "output_directory = \"./\"\n",
    "\n",
    "# Save as an SRT file\n",
    "srt_writer = get_writer(\"srt\", output_directory)\n",
    "srt_writer(result, audio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
