{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai --upgrade\n",
    "! pip install langchain --upgrade\n",
    "! pip install python-dotenv\n",
    "! pip install srt\n",
    "! pip install codecs\n",
    "! pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import langchain as lc\n",
    "from langchain.document_loaders import SRTLoader\n",
    "from dotenv import load_dotenv\n",
    "import srt\n",
    "import codecs\n",
    "import tiktoken\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "GPT_MODEL_NAME = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def get_completion(prompt, model=GPT_MODEL_NAME):\n",
    "    response = client.chat.completions.create(\n",
    "        temperature=0, \n",
    "        model=GPT_MODEL_NAME, \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant with expertise in english language reading and writing. You are an expert copywriter.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def write_to_file(content: str, file_path: str):\n",
    "    \"\"\"Write content to a file.\"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_srt_file(file_path: str):\n",
    "    \"\"\"Read and parse an SRT file.\"\"\"\n",
    "    with codecs.open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        return list(srt.parse(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio download from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Improved: Added error handling and streamlined audio format\n",
    "\n",
    "def download_video(youtube_link: str, output_filename: str = \"stream\"):\n",
    "    \"\"\"Downloads the video stream from a YouTube video.\"\"\"\n",
    "    try:\n",
    "        youtube = YouTube(youtube_link)\n",
    "        # Selecting the best audio stream\n",
    "        video_stream = youtube.streams.first()\n",
    "        if not video_stream:\n",
    "            raise Exception(\"No video stream found in the YouTube video.\")\n",
    "\n",
    "        # Downloading and saving the stream\n",
    "        video_stream.download(filename=f\"{output_filename}.mp4\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "\n",
    "# YouTube video URL\n",
    "url = 'https://www.youtube.com/watch?v=LUk7INpXM5M'\n",
    "\n",
    "download_video(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Audio from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_name = \"stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def extract_audio(video_file: str, audio_file: str):\n",
    "    \"\"\"Extracts audio from a video file and saves it as an audio file.\"\"\"\n",
    "    try:\n",
    "        with VideoFileClip(video_file) as video:\n",
    "            audio = video.audio\n",
    "            audio.write_audiofile(audio_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting audio: {e}\")\n",
    "\n",
    "# Usage\n",
    "extract_audio(f\"{video_file_name}.mp4\", \"output_audio.mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! pip uninstall whisper\n",
    "! pip install git+https://github.com/openai/whisper.git\n",
    "! pip install pydub \n",
    "! pip install ffmpeg\n",
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA Available: {is_cuda_available}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from whisper.utils import get_writer\n",
    "import re\n",
    "\n",
    "def split_on_punctuation_or_space(text, max_length):\n",
    "    \"\"\"\n",
    "    Splits the text on punctuation marks first, if any segments are longer than max_length,\n",
    "    then split on spaces as a fallback.\n",
    "    \"\"\"\n",
    "    punctuated_splits = re.split(r'(?<=[.!?]) +', text)\n",
    "    final_splits = []\n",
    "    for segment in punctuated_splits:\n",
    "        if len(segment) > max_length:\n",
    "            # Further split long segments at the nearest space to the halfway point\n",
    "            space_splits = segment.split(' ')\n",
    "            part = \"\"\n",
    "            for word in space_splits:\n",
    "                if len(part + word) < max_length:\n",
    "                    part += word + \" \"\n",
    "                else:\n",
    "                    final_splits.append(part.strip())\n",
    "                    part = word + \" \"  # Start a new part\n",
    "            final_splits.append(part.strip())  # Add the last part for this segment\n",
    "        else:\n",
    "            final_splits.append(segment)\n",
    "    return final_splits\n",
    "\n",
    "def estimate_time_per_word(total_duration, total_words):\n",
    "    return total_duration / total_words if total_words > 0 else 0\n",
    "\n",
    "def split_transcript_segments(result, max_segment_duration=10):\n",
    "    new_segments = []\n",
    "    for segment in result['segments']:\n",
    "        segment_duration = segment['end'] - segment['start']\n",
    "        words = segment['text'].split()\n",
    "        time_per_word = estimate_time_per_word(segment_duration, len(words))\n",
    "        \n",
    "        # Estimate max length of segment text based on duration\n",
    "        max_words_per_segment = max_segment_duration / time_per_word if time_per_word > 0 else 10\n",
    "        max_length = int(max_words_per_segment * 10)  # Estimate average word length\n",
    "\n",
    "        split_texts = split_on_punctuation_or_space(segment['text'], max_length)\n",
    "        \n",
    "        current_start_time = segment['start']\n",
    "        for split_text in split_texts:\n",
    "            split_words = split_text.split()\n",
    "            split_duration = len(split_words) * time_per_word\n",
    "            new_segments.append({\n",
    "                'start': current_start_time,\n",
    "                'end': current_start_time + split_duration,\n",
    "                'text': split_text,\n",
    "            })\n",
    "            current_start_time += split_duration\n",
    "    return new_segments\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "audio = \"output_audio.mp3\"\n",
    "result = model.transcribe(audio)\n",
    "\n",
    "# Apply sophisticated splitting\n",
    "result['segments'] = split_transcript_segments(result)\n",
    "\n",
    "output_directory = \"./\"\n",
    "\n",
    "# Save as an SRT file\n",
    "try:\n",
    "    srt_writer = get_writer(\"srt\", output_directory)\n",
    "    srt_writer(result, audio)\n",
    "    print(f\"SRT file saved.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving SRT file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReSplit SRT File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import timedelta\n",
    "\n",
    "def parse_srt_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    patterns = re.compile(r'(\\d+)\\n(\\d{2}:\\d{2}:\\d{2},\\d{3}) --> (\\d{2}:\\d{2}:\\d{2},\\d{3})\\n(.*?)\\n\\n', re.DOTALL)\n",
    "    subtitles = []\n",
    "    for match in patterns.finditer(content):\n",
    "        index, start, end, text = match.groups()\n",
    "        subtitles.append({'start': start, 'end': end, 'text': text})\n",
    "    return subtitles\n",
    "\n",
    "def srt_time_to_seconds(srt_time):\n",
    "    hours, minutes, seconds_milliseconds = srt_time.split(':')\n",
    "    seconds, milliseconds = seconds_milliseconds.split(',')\n",
    "    total_seconds = int(hours) * 3600 + int(minutes) * 60 + int(seconds) + int(milliseconds) / 1000\n",
    "    return total_seconds\n",
    "\n",
    "def seconds_to_srt_time(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = seconds % 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{int(seconds):02},{milliseconds:03}\"\n",
    "\n",
    "\n",
    "def write_srt_file(subtitles, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for i, subtitle in enumerate(subtitles, start=1):\n",
    "            file.write(f\"{i}\\n{subtitle['start']} --> {subtitle['end']}\\n{subtitle['text']}\\n\\n\")\n",
    "\n",
    "# Use the previously defined functions for splitting logic\n",
    "# Assuming split_on_punctuation_or_space and split_transcript_segments are already defined\n",
    "\n",
    "def improve_srt_file(input_filename, output_filename):\n",
    "    subtitles = parse_srt_file(input_filename)\n",
    "    improved_subtitles = []\n",
    "    for subtitle in subtitles:\n",
    "        start_seconds = srt_time_to_seconds(subtitle['start'])\n",
    "        end_seconds = srt_time_to_seconds(subtitle['end'])\n",
    "        duration = end_seconds - start_seconds\n",
    "        text = subtitle['text']\n",
    "        \n",
    "        # Assuming an average reading speed or adjust according to your preferences\n",
    "        max_segment_duration = 10\n",
    "        split_texts = split_on_punctuation_or_space(text, 60)  # Assuming 60 characters as a rough split\n",
    "        \n",
    "        time_per_split = duration / len(split_texts)\n",
    "        for i, split_text in enumerate(split_texts):\n",
    "            improved_subtitles.append({\n",
    "                'start': seconds_to_srt_time(start_seconds + i * time_per_split),\n",
    "                'end': seconds_to_srt_time(start_seconds + (i + 1) * time_per_split),\n",
    "                'text': split_text\n",
    "            })\n",
    "    \n",
    "    write_srt_file(improved_subtitles, output_filename)\n",
    "\n",
    "# Example usage\n",
    "input_srt_filename = '2024-03-11-Prompt-Engineering-Kariyeri.srt'\n",
    "output_srt_filename = '2024-03-11-Prompt-Engineering-Kariyeri-2.srt'\n",
    "improve_srt_file(input_srt_filename, output_srt_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating video chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subtitles(subtitles, model_name: str):\n",
    "    \"\"\"Process subtitles and split them into chapters.\"\"\"\n",
    "    result, chunk = \"\", \"\"\n",
    "    for sub in subtitles:\n",
    "        chunk += f\"{sub.start}>{sub.end.total_seconds()}\\n{sub.content}\"\n",
    "        if num_tokens_from_string(chunk) > 7000:\n",
    "            result += split_into_chapters(chunk, model_name)\n",
    "            chunk = \"\"        \n",
    "    if chunk:\n",
    "        result += split_into_chapters(chunk, model_name)\n",
    "    return result\n",
    "\n",
    "def split_into_chapters(chunk: str, model_name: str):\n",
    "    \"\"\"Split the transcript chunk into chapters.\"\"\"\n",
    "    prompt = (\"Below is a part of a video transcript. You need to split the video \"\n",
    "              \"into five topic chapters. The chapters will be used to navigate in the \"\n",
    "              \"larger video timeline to let watchers switch between topics. Read the \"\n",
    "              \"entire transcript. Once done reading, split it into chapters. Provide \"\n",
    "              \"the list of chapters in this format [HH:MM:SS Chapter Name in Turkish]. Put each \"\n",
    "              \"chapter in a separate line in plain text using the transcript language. \\n\\n\" + chunk)\n",
    "    return get_completion(prompt, model_name)\n",
    "\n",
    "\n",
    "subtitles = read_srt_file(\"output_audio.srt\")\n",
    "final_output = process_subtitles(subtitles, GPT_MODEL_NAME)\n",
    "write_to_file(final_output, 'chapters-iac.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating video summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary(transcript: str, model_name: str):\n",
    "    \"\"\"Create a summary of the given transcript.\"\"\"\n",
    "    prompt = (\"Below is a video transcript. Your goal is to summarize the \"\n",
    "              \"entire video. You need to create the shortest summary as possible \"\n",
    "              \" that will help a reader understand the information given in the video. \"\n",
    "              \"Your summary should be in Turkish.\\n\\n\" + transcript)\n",
    "    return get_completion(prompt, model_name)\n",
    "\n",
    "subtitles = read_srt_file(\"output_audio.srt\")\n",
    "transcript_text = \"\\n\\n\".join([f\"{sub.content}\" for sub in subtitles])\n",
    "final_output = create_summary(transcript_text, GPT_MODEL_NAME)\n",
    "write_to_file(final_output, 'summaries.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_srt_file(file_path: str, model_name: str):\n",
    "    \"\"\"Process an SRT file to generate Turkish title alternatives and a summary.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    prompt = (\"Below is a series of summaries created out of different sections \"\n",
    "              \"of a video recording. The video is published on YouTube. Provide \"\n",
    "              \"10 Turkish title alternatives and a single Turkish summary for the \"\n",
    "              \"video. Both title and summary should be inviting and helpful to \"\n",
    "              \"watchers.\\n\\n\" + content)\n",
    "    \n",
    "    return get_completion(prompt, model_name)\n",
    "\n",
    "final_output = process_srt_file(\"summaries.txt\", GPT_MODEL_NAME)\n",
    "with open('title-description.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
