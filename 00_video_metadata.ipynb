{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai --upgrade\n",
    "! pip install langchain --upgrade\n",
    "! pip install python-dotenv\n",
    "! pip install srt\n",
    "! pip install codecs\n",
    "! pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import langchain as lc\n",
    "from langchain.document_loaders import SRTLoader\n",
    "from dotenv import load_dotenv\n",
    "import srt\n",
    "import codecs\n",
    "import tiktoken\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables.\")\n",
    "\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "GPT_MODEL_NAME = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def get_completion(prompt, model=GPT_MODEL_NAME):\n",
    "    response = client.chat.completions.create(\n",
    "        temperature=0, \n",
    "        model=GPT_MODEL_NAME, \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant with expertise in english language reading and writing. You are an expert copywriter.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def write_to_file(content: str, file_path: str):\n",
    "    \"\"\"Write content to a file.\"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_srt_file(file_path: str):\n",
    "    \"\"\"Read and parse an SRT file.\"\"\"\n",
    "    with codecs.open(file_path, 'r', encoding='utf-8-sig') as f:\n",
    "        return list(srt.parse(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio download from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Improved: Added error handling and streamlined audio format\n",
    "\n",
    "def download_video(youtube_link: str, output_filename: str = \"stream\"):\n",
    "    \"\"\"Downloads the video stream from a YouTube video.\"\"\"\n",
    "    try:\n",
    "        youtube = YouTube(youtube_link)\n",
    "        # Selecting the best audio stream\n",
    "        video_stream = youtube.streams.first()\n",
    "        if not video_stream:\n",
    "            raise Exception(\"No video stream found in the YouTube video.\")\n",
    "\n",
    "        # Downloading and saving the stream\n",
    "        video_stream.download(filename=f\"{output_filename}.mp4\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "\n",
    "# YouTube video URL\n",
    "url = 'https://www.youtube.com/watch?v=LUk7INpXM5M'\n",
    "\n",
    "download_video(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Audio from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_name = \"stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def extract_audio(video_file: str, audio_file: str):\n",
    "    \"\"\"Extracts audio from a video file and saves it as an audio file.\"\"\"\n",
    "    try:\n",
    "        with VideoFileClip(video_file) as video:\n",
    "            audio = video.audio\n",
    "            audio.write_audiofile(audio_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting audio: {e}\")\n",
    "\n",
    "# Usage\n",
    "extract_audio(f\"{video_file_name}.mp4\", \"output_audio.mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! pip uninstall whisper\n",
    "! pip install git+https://github.com/openai/whisper.git\n",
    "! pip install pydub \n",
    "! pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA Available: {is_cuda_available}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from whisper.utils import get_writer\n",
    "from pydub import AudioSegment\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "audio = \"output_audio.mp3\"\n",
    "result = model.transcribe(audio)\n",
    "output_directory = \"./\"\n",
    "\n",
    "# Save as an SRT file\n",
    "try:\n",
    "    srt_writer = get_writer(\"srt\", output_directory)\n",
    "    srt_writer(result, audio)\n",
    "    print(f\"SRT file saved.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving SRT file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating video chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subtitles(subtitles, model_name: str):\n",
    "    \"\"\"Process subtitles and split them into chapters.\"\"\"\n",
    "    result, chunk = \"\", \"\"\n",
    "    for sub in subtitles:\n",
    "        chunk += f\"{sub.start}>{sub.end.total_seconds()}\\n{sub.content}\"\n",
    "        if num_tokens_from_string(chunk) > 7000:\n",
    "            result += split_into_chapters(chunk, model_name)\n",
    "            chunk = \"\"        \n",
    "    if chunk:\n",
    "        result += split_into_chapters(chunk, model_name)\n",
    "    return result\n",
    "\n",
    "def split_into_chapters(chunk: str, model_name: str):\n",
    "    \"\"\"Split the transcript chunk into chapters.\"\"\"\n",
    "    prompt = (\"Below is a part of a video transcript. You need to split the video \"\n",
    "              \"into five topic chapters. The chapters will be used to navigate in the \"\n",
    "              \"larger video timeline to let watchers switch between topics. Read the \"\n",
    "              \"entire transcript. Once done reading, split it into chapters. Provide \"\n",
    "              \"the list of chapters in this format [HH:MM:SS Chapter Name in Turkish]. Put each \"\n",
    "              \"chapter in a separate line in plain text using the transcript language. \\n\\n\" + chunk)\n",
    "    return get_completion(prompt, model_name)\n",
    "\n",
    "\n",
    "subtitles = read_srt_file(\"output_audio.srt\")\n",
    "final_output = process_subtitles(subtitles, GPT_MODEL_NAME)\n",
    "write_to_file(final_output, 'chapters-iac.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating video summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary(transcript: str, model_name: str):\n",
    "    \"\"\"Create a summary of the given transcript.\"\"\"\n",
    "    prompt = (\"Below is a video transcript. Your goal is to summarize the \"\n",
    "              \"entire video. You need to create the shortest summary as possible \"\n",
    "              \" that will help a reader understand the information given in the video. \"\n",
    "              \"Your summary should be in Turkish.\\n\\n\" + transcript)\n",
    "    return get_completion(prompt, model_name)\n",
    "\n",
    "subtitles = read_srt_file(\"output_audio.srt\")\n",
    "transcript_text = \"\\n\\n\".join([f\"{sub.content}\" for sub in subtitles])\n",
    "final_output = create_summary(transcript_text, GPT_MODEL_NAME)\n",
    "write_to_file(final_output, 'summaries.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_srt_file(file_path: str, model_name: str):\n",
    "    \"\"\"Process an SRT file to generate Turkish title alternatives and a summary.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    prompt = (\"Below is a series of summaries created out of different sections \"\n",
    "              \"of a video recording. The video is published on YouTube. Provide \"\n",
    "              \"10 Turkish title alternatives and a single Turkish summary for the \"\n",
    "              \"video. Both title and summary should be inviting and helpful to \"\n",
    "              \"watchers.\\n\\n\" + content)\n",
    "    \n",
    "    return get_completion(prompt, model_name)\n",
    "\n",
    "final_output = process_srt_file(\"summaries.txt\", GPT_MODEL_NAME)\n",
    "with open('title-description.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
